# Self-hosted chat model
- name: gemma3
  provider: ollama
  model: gemma3:12b
  max_tokens: 4096
  streaming: true

# Self-hosted chat model with tools
- name: mistral
  provider: ollama
  model: mistral:7b-instruct
  max_tokens: 4096
  streaming: true

# Self-hosted embedding model
- name: nomic-embed-text
  provider: ollama
  model: nomic-embed-text

# OpenAI fast model
- name: gpt35-turbo
  provider: openai
  model: gpt-3.5-turbo
  api_key: !env OPENAI_API_KEY
  max_tokens: 2048
  temperature: 0.7
  streaming: true

# Chat model using GPT-4o
- name: gpt4o-chat
  provider: openai
  model: gpt-4o
  api_key: !env OPENAI_API_KEY
  max_tokens: 4096
  temperature: 0.7
  streaming: true

# Mid-size chat model
- name: gpt4o-mini
  provider: openai
  model: o4-mini
  api_key: !env OPENAI_API_KEY
  max_tokens: 4096
  streaming: True
  verbose: True
  
